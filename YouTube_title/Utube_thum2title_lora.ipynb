{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d58946",
   "metadata": {},
   "source": [
    "--- \n",
    "ê¸ˆì¼ ìˆ˜ì§‘ ë°ì´í„° merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41c6dcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1208'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from pathlib import Path\n",
    "\n",
    "folder = Path(\"Utube_data\") / \"data_collect\" / \"Utube_data\" / \"data_collect\" / \"collect\"\n",
    "\n",
    "csv_files = list(folder.glob('*.csv'))\n",
    "\n",
    "file_names = [f.name for f in csv_files]\n",
    "file_data = str(file_names).split('-')[0]\n",
    "file_data[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c95c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_merge_df(root= './Utube_data/data_collect/Utube_data/data_collect/collect/'):\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "\n",
    "    folder = Path(root)\n",
    "    csv_files = list(folder.glob('*.csv'))\n",
    "\n",
    "    file_names = [f.name for f in csv_files]\n",
    "    file_data = str(file_names).split('-')[0]\n",
    "    file_data = file_data[-4:]\n",
    "\n",
    "    df_list = []\n",
    "\n",
    "    for file in csv_files:\n",
    "        temp_df = pd.read_csv(file)\n",
    "        df_list.append(temp_df)\n",
    "\n",
    "    merged_df = pd.concat(df_list, ignore_index=True)\n",
    "    merged_df = merged_df.sort_values('created_at')\n",
    "    merged_df = merged_df.drop_duplicates(subset='videoId' ,keep='last')\n",
    "    \n",
    "    merged_df = merged_df.to_csv(f'./Utube_data/data/youtubedata-{file_data}.csv',index=False)\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6a5deae",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_merge_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c58078",
   "metadata": {},
   "source": [
    "---\n",
    "ì „ì²´ ìˆ˜ì§‘ ë°ì´í„° merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94591026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df(root):\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "\n",
    "    folder = Path(root)\n",
    "    csv_files = list(folder.glob('*.csv'))\n",
    "\n",
    "    df_list = []\n",
    "\n",
    "    for file in csv_files:\n",
    "        temp_df = pd.read_csv(file)\n",
    "        df_list.append(temp_df)\n",
    "\n",
    "    merged_df = pd.concat(df_list, ignore_index=True)\n",
    "    merged_df = merged_df.sort_values('created_at')\n",
    "    merged_df = merged_df.drop_duplicates(subset='videoId' ,keep='last')\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a2517b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5661 entries, 2227 to 13266\n",
      "Data columns (total 18 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   id               5661 non-null   int64 \n",
      " 1   videoId          5661 non-null   object\n",
      " 2   title            5661 non-null   object\n",
      " 3   description      3544 non-null   object\n",
      " 4   channelTitle     5661 non-null   object\n",
      " 5   publishedAt      5661 non-null   object\n",
      " 6   category         5661 non-null   object\n",
      " 7   shortsHashtags   1115 non-null   object\n",
      " 8   fetchedDate      5661 non-null   object\n",
      " 9   business_date    5661 non-null   object\n",
      " 10  viewCount        5661 non-null   int64 \n",
      " 11  likeCount        5661 non-null   int64 \n",
      " 12  commentCount     5661 non-null   int64 \n",
      " 13  subscriberCount  5661 non-null   int64 \n",
      " 14  channelTier      5661 non-null   object\n",
      " 15  url              5661 non-null   object\n",
      " 16  created_at       1901 non-null   object\n",
      " 17  thumbnail_url    174 non-null    object\n",
      "dtypes: int64(5), object(13)\n",
      "memory usage: 840.3+ KB\n"
     ]
    }
   ],
   "source": [
    "merge_df = merge_df('./Utube_data/data')\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "today = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "merge_df.to_csv(f\"./Utube_data/youtube_merge_{today}.csv\", index=False)\n",
    "merge_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a14431",
   "metadata": {},
   "source": [
    "---\n",
    "ì˜ˆì „ì— ìˆ˜ì§‘í–ˆë˜ ë°ì´í„°ë“¤ê³¼ í•©ì³¤ì–´ì„œ ì¸ë„¤ì¼ urlì´ ìˆëŠ” ë°ì´í„°ë§Œ ê°€ì ¸ì˜´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e44d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merge_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "114b7256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>videoId</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>category</th>\n",
       "      <th>shortsHashtags</th>\n",
       "      <th>fetchedDate</th>\n",
       "      <th>business_date</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>subscriberCount</th>\n",
       "      <th>channelTier</th>\n",
       "      <th>url</th>\n",
       "      <th>created_at</th>\n",
       "      <th>thumbnail_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>6eVIT1NvSm4</td>\n",
       "      <td>ì†ì˜¤ê³µ,ì¹ ì„ ê³µì£¼ 2025ë…„ ì• ë‹ˆë©”ì´ì…˜ í•„ë¦„ ë””ì§€í„¸ ë³µì› í¬ëŸ¼</td>\n",
       "      <td>ì†ì˜¤ê³µ,ì¹ ì„ ê³µì£¼ 2025ë…„ ì• ë‹ˆë©”ì´ì…˜ í•„ë¦„ ë””ì§€í„¸ ë³µì› í¬ëŸ¼\\n\\në¶€ì²œêµ­ì œíŒíƒ€ìŠ¤í‹±ì˜...</td>\n",
       "      <td>ê´´ìˆ˜ì˜ì™• Movie Monster</td>\n",
       "      <td>2025-07-05 10:39:32</td>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>#ì†ì˜¤ê³µ, #ì¹ ì„ ê³µì£¼, #ì„œìœ ê¸°, #ì„¸ê¸°ìƒì‚¬, #í•œêµ­ì˜ìƒìë£Œì›, #ì˜ìƒìë£Œì›, #ì†...</td>\n",
       "      <td>2025-12-04 19:00:00</td>\n",
       "      <td>2025-12-04</td>\n",
       "      <td>364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13500</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>https://www.youtube.com/watch?v=6eVIT1NvSm4</td>\n",
       "      <td>2025-12-04 19:00:00</td>\n",
       "      <td>https://i.ytimg.com/vi/6eVIT1NvSm4/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3yY6hkwkaOY</td>\n",
       "      <td>Exodus Part 7 â€” â€œThe Plague of Fliesâ€ Shorts  ...</td>\n",
       "      <td>Exodus Part 7 â€” â€œThe Plague of Fliesâ€ | ì¶œì• êµ½ê¸° 7...</td>\n",
       "      <td>BibleTokTok</td>\n",
       "      <td>2025-11-06 03:46:38</td>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>#bibletoktok, #movie, #bible, #animation, #Exo...</td>\n",
       "      <td>2025-12-04 19:00:00</td>\n",
       "      <td>2025-12-04</td>\n",
       "      <td>1108</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>299</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>https://www.youtube.com/watch?v=3yY6hkwkaOY</td>\n",
       "      <td>2025-12-04 19:00:00</td>\n",
       "      <td>https://i.ytimg.com/vi/3yY6hkwkaOY/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>QHfIUXvr3xc</td>\n",
       "      <td>Sugar on my ğŸ‘… #ì¶¤ì¶”ëŠ”ì„œìœ¤ #ì¶¤ì¶”ëŠ”ê³°ëŒ #ëŒ„ìŠ¤ #dance #kpop #...</td>\n",
       "      <td>ì•ˆë…•í•˜ì„¸ìš” afstarz  ì‹ ì„œìœ¤ì…ë‹ˆë‹¤^^\\nêµ¬ë…ê³¼ ì¢‹ì•„ìš” í•´ì£¼ì‹œëŠ”ë¶„ë“¤ ë„ˆë¬´ ê°ì‚¬ë“œ...</td>\n",
       "      <td>ì¶¤ì¶”ëŠ”ì„œìœ¤</td>\n",
       "      <td>2025-12-03 18:00:46</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-12-04 19:00:00</td>\n",
       "      <td>2025-12-04</td>\n",
       "      <td>5699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302000</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>https://www.youtube.com/watch?v=QHfIUXvr3xc</td>\n",
       "      <td>2025-12-04 19:00:00</td>\n",
       "      <td>https://i.ytimg.com/vi/QHfIUXvr3xc/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>ksmZypA9aak</td>\n",
       "      <td>ê·¹ë½ ì°¨ë°•ì˜ ì‹œì‘ [ì¹´ë‹ˆë°œ íšŒì „ì‹œíŠ¸]</td>\n",
       "      <td>#ì°¨ë°• #ì¹´ë‹ˆë°œ #shorts</td>\n",
       "      <td>ìœ¤ìŠ¤ìº í¼</td>\n",
       "      <td>2025-12-03 15:15:59</td>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "      <td>#ì°¨ë°•, #ì¹´ë‹ˆë°œ, #shorts</td>\n",
       "      <td>2025-12-04 19:00:00</td>\n",
       "      <td>2025-12-04</td>\n",
       "      <td>2464</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>19600</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>https://www.youtube.com/watch?v=ksmZypA9aak</td>\n",
       "      <td>2025-12-04 19:00:00</td>\n",
       "      <td>https://i.ytimg.com/vi/ksmZypA9aak/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>HArxveHj8k0</td>\n",
       "      <td>á„Œá…®á†¼á„€á…©á„á…¡ á„ƒá…µá†¯á„…á…¥á„€á…¡ á„Œá…¥á†¯á„ƒá…¢ á„‹á…¡á†« á„á…¡á„‚á…³á†« á„á…¡ #ì¤‘ê³ ì°¨</td>\n",
       "      <td>â–¼êµ­ì‚°,ìˆ˜ì… ì°¨íŒŒëŠ”ê±¸ ë§¤ë¬¼ë³´ê¸°â–¼\\nhttp://www.xn--369aw9ii7yvj...</td>\n",
       "      <td>ì°¨íŒŒëŠ”ê±¸</td>\n",
       "      <td>2025-12-01 14:30:16</td>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-12-04 19:00:00</td>\n",
       "      <td>2025-12-04</td>\n",
       "      <td>3826</td>\n",
       "      <td>65</td>\n",
       "      <td>19</td>\n",
       "      <td>103000</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>https://www.youtube.com/watch?v=HArxveHj8k0</td>\n",
       "      <td>2025-12-04 19:00:00</td>\n",
       "      <td>https://i.ytimg.com/vi/HArxveHj8k0/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>182</td>\n",
       "      <td>pMZtk7XNc1Y</td>\n",
       "      <td>ëˆˆê¸¸ ìš´ì „ ì‚¬ê³  ë°©ì§€ìš© ì•„ì´í…œ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ìœ¤í‚¤ë¼ì´ë“œ</td>\n",
       "      <td>2025-12-08 11:00:54</td>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-12-08 13:10:00</td>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>1158</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>63700</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>https://www.youtube.com/watch?v=pMZtk7XNc1Y</td>\n",
       "      <td>2025-12-08 13:10:00</td>\n",
       "      <td>https://i.ytimg.com/vi/pMZtk7XNc1Y/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>181</td>\n",
       "      <td>QZFW_JL8E40</td>\n",
       "      <td>ì˜µì…˜ ë§ì€ ë² ìŠ¤íŠ¸ ì…€ë ‰ì…˜II 2ì²œë§Œ ì›ëŒ€ íŠ¹ê°€ 2021ë…„í˜• ë”K9 3.8 4ë¥œ ì»¬ëŸ¬...</td>\n",
       "      <td>ë” ë§ì€~ ì¤‘ê³ ì°¨ë¥¼ ë³´ê³  ì‹¶ë‹¤ë©´?  \"ë‹¤ë‘¥ì´ì°¨ ê³µì‹ ì‚¬ì´íŠ¸ ì£¼ì†Œ í´ë¦­!\" \\nwww...</td>\n",
       "      <td>ë‹¤ë‘¥ì´ì°¨</td>\n",
       "      <td>2025-12-08 12:00:29</td>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "      <td>#ë”K9, #ë”K9ì¤‘ê³ , #ë”K9ì¤‘ê³ ê°€ê²©, #ë”Kë² ì´ì§€ì‹œíŠ¸, #K9, #K9ì¤‘ê³ , ...</td>\n",
       "      <td>2025-12-08 13:10:00</td>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>318</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>33400</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>https://www.youtube.com/watch?v=QZFW_JL8E40</td>\n",
       "      <td>2025-12-08 13:10:00</td>\n",
       "      <td>https://i.ytimg.com/vi/QZFW_JL8E40/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>180</td>\n",
       "      <td>hitC3ZG4dTI</td>\n",
       "      <td>500~600ë§Œì›ëŒ€ ì¤‘ê³ ì°¨ì˜ ì•ˆíƒ€ê¹Œìš´ í˜„ì‹¤ğŸ˜‡</td>\n",
       "      <td>ìˆ˜ì› ë„ì´ì¹˜ì˜¤í† ì›”ë“œ ì¤‘ê³ ì°¨ ë§¤ë„ˆëª¨ë“œğŸ˜\\n\\në¬´ë£Œìƒë‹´ : 010-5333-9953\\n...</td>\n",
       "      <td>ì¤‘ê³ ì°¨ ë§¤ë„ˆëª¨ë“œ</td>\n",
       "      <td>2025-12-08 12:32:35</td>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-12-08 13:10:00</td>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>3601</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50500</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>https://www.youtube.com/watch?v=hitC3ZG4dTI</td>\n",
       "      <td>2025-12-08 13:10:00</td>\n",
       "      <td>https://i.ytimg.com/vi/hitC3ZG4dTI/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>186</td>\n",
       "      <td>s2S0jPX4BI4</td>\n",
       "      <td>ğŸ‡ºğŸ‡¸ ğŸ’¥ Impossible! Tallest Golfer Pulls Off Jaw-...</td>\n",
       "      <td>ğŸ‡ºğŸ‡¸ ğŸ’¥ Impossible! Tallest Golfer Pulls Off Jaw-...</td>\n",
       "      <td>BrightSide</td>\n",
       "      <td>2025-12-08 12:56:58</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>#Golf, #TallestGolfer, #JawDropping, #Shocking...</td>\n",
       "      <td>2025-12-08 13:10:00</td>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68900</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>https://www.youtube.com/watch?v=s2S0jPX4BI4</td>\n",
       "      <td>2025-12-08 13:10:00</td>\n",
       "      <td>https://i.ytimg.com/vi/s2S0jPX4BI4/maxresdefau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>193</td>\n",
       "      <td>DPqVzUZUltA</td>\n",
       "      <td>ìˆœê°„ì ìœ¼ë¡œ  í´ëŠ” ìš”ì¶”ì˜ ë¹„í‹€ë¦¼Instantly stretch the twistin...</td>\n",
       "      <td>ìˆœê°„ì ìœ¼ë¡œ í´ëŠ” ìš”ì¶”ì˜ ë¹„í‹€ë¦¼\\nInstantly stretch the twisti...</td>\n",
       "      <td>å¥‡è¹Ÿç‘œä¼½Miracle Yoga</td>\n",
       "      <td>2025-12-08 11:30:12</td>\n",
       "      <td>Sports</td>\n",
       "      <td>#yoga, #stretch, #sports</td>\n",
       "      <td>2025-12-08 13:10:00</td>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19100</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>https://www.youtube.com/watch?v=DPqVzUZUltA</td>\n",
       "      <td>2025-12-08 13:10:00</td>\n",
       "      <td>https://i.ytimg.com/vi/DPqVzUZUltA/maxresdefau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      videoId                                              title  \\\n",
       "0     22  6eVIT1NvSm4                  ì†ì˜¤ê³µ,ì¹ ì„ ê³µì£¼ 2025ë…„ ì• ë‹ˆë©”ì´ì…˜ í•„ë¦„ ë””ì§€í„¸ ë³µì› í¬ëŸ¼   \n",
       "1      3  3yY6hkwkaOY  Exodus Part 7 â€” â€œThe Plague of Fliesâ€ Shorts  ...   \n",
       "2    103  QHfIUXvr3xc  Sugar on my ğŸ‘… #ì¶¤ì¶”ëŠ”ì„œìœ¤ #ì¶¤ì¶”ëŠ”ê³°ëŒ #ëŒ„ìŠ¤ #dance #kpop #...   \n",
       "3     36  ksmZypA9aak                               ê·¹ë½ ì°¨ë°•ì˜ ì‹œì‘ [ì¹´ë‹ˆë°œ íšŒì „ì‹œíŠ¸]   \n",
       "4     39  HArxveHj8k0            á„Œá…®á†¼á„€á…©á„á…¡ á„ƒá…µá†¯á„…á…¥á„€á…¡ á„Œá…¥á†¯á„ƒá…¢ á„‹á…¡á†« á„á…¡á„‚á…³á†« á„á…¡ #ì¤‘ê³ ì°¨   \n",
       "..   ...          ...                                                ...   \n",
       "169  182  pMZtk7XNc1Y                                   ëˆˆê¸¸ ìš´ì „ ì‚¬ê³  ë°©ì§€ìš© ì•„ì´í…œ   \n",
       "170  181  QZFW_JL8E40  ì˜µì…˜ ë§ì€ ë² ìŠ¤íŠ¸ ì…€ë ‰ì…˜II 2ì²œë§Œ ì›ëŒ€ íŠ¹ê°€ 2021ë…„í˜• ë”K9 3.8 4ë¥œ ì»¬ëŸ¬...   \n",
       "171  180  hitC3ZG4dTI                           500~600ë§Œì›ëŒ€ ì¤‘ê³ ì°¨ì˜ ì•ˆíƒ€ê¹Œìš´ í˜„ì‹¤ğŸ˜‡   \n",
       "172  186  s2S0jPX4BI4  ğŸ‡ºğŸ‡¸ ğŸ’¥ Impossible! Tallest Golfer Pulls Off Jaw-...   \n",
       "173  193  DPqVzUZUltA  ìˆœê°„ì ìœ¼ë¡œ  í´ëŠ” ìš”ì¶”ì˜ ë¹„í‹€ë¦¼Instantly stretch the twistin...   \n",
       "\n",
       "                                           description        channelTitle  \\\n",
       "0    ì†ì˜¤ê³µ,ì¹ ì„ ê³µì£¼ 2025ë…„ ì• ë‹ˆë©”ì´ì…˜ í•„ë¦„ ë””ì§€í„¸ ë³µì› í¬ëŸ¼\\n\\në¶€ì²œêµ­ì œíŒíƒ€ìŠ¤í‹±ì˜...  ê´´ìˆ˜ì˜ì™• Movie Monster   \n",
       "1    Exodus Part 7 â€” â€œThe Plague of Fliesâ€ | ì¶œì• êµ½ê¸° 7...         BibleTokTok   \n",
       "2    ì•ˆë…•í•˜ì„¸ìš” afstarz  ì‹ ì„œìœ¤ì…ë‹ˆë‹¤^^\\nêµ¬ë…ê³¼ ì¢‹ì•„ìš” í•´ì£¼ì‹œëŠ”ë¶„ë“¤ ë„ˆë¬´ ê°ì‚¬ë“œ...               ì¶¤ì¶”ëŠ”ì„œìœ¤   \n",
       "3                                     #ì°¨ë°• #ì¹´ë‹ˆë°œ #shorts                ìœ¤ìŠ¤ìº í¼   \n",
       "4    â–¼êµ­ì‚°,ìˆ˜ì… ì°¨íŒŒëŠ”ê±¸ ë§¤ë¬¼ë³´ê¸°â–¼\\nhttp://www.xn--369aw9ii7yvj...                ì°¨íŒŒëŠ”ê±¸   \n",
       "..                                                 ...                 ...   \n",
       "169                                                NaN               ìœ¤í‚¤ë¼ì´ë“œ   \n",
       "170  ë” ë§ì€~ ì¤‘ê³ ì°¨ë¥¼ ë³´ê³  ì‹¶ë‹¤ë©´?  \"ë‹¤ë‘¥ì´ì°¨ ê³µì‹ ì‚¬ì´íŠ¸ ì£¼ì†Œ í´ë¦­!\" \\nwww...                ë‹¤ë‘¥ì´ì°¨   \n",
       "171  ìˆ˜ì› ë„ì´ì¹˜ì˜¤í† ì›”ë“œ ì¤‘ê³ ì°¨ ë§¤ë„ˆëª¨ë“œğŸ˜\\n\\në¬´ë£Œìƒë‹´ : 010-5333-9953\\n...            ì¤‘ê³ ì°¨ ë§¤ë„ˆëª¨ë“œ   \n",
       "172  ğŸ‡ºğŸ‡¸ ğŸ’¥ Impossible! Tallest Golfer Pulls Off Jaw-...          BrightSide   \n",
       "173  ìˆœê°„ì ìœ¼ë¡œ í´ëŠ” ìš”ì¶”ì˜ ë¹„í‹€ë¦¼\\nInstantly stretch the twisti...    å¥‡è¹Ÿç‘œä¼½Miracle Yoga   \n",
       "\n",
       "             publishedAt          category  \\\n",
       "0    2025-07-05 10:39:32  Film & Animation   \n",
       "1    2025-11-06 03:46:38  Film & Animation   \n",
       "2    2025-12-03 18:00:46    People & Blogs   \n",
       "3    2025-12-03 15:15:59  Autos & Vehicles   \n",
       "4    2025-12-01 14:30:16  Autos & Vehicles   \n",
       "..                   ...               ...   \n",
       "169  2025-12-08 11:00:54  Autos & Vehicles   \n",
       "170  2025-12-08 12:00:29  Autos & Vehicles   \n",
       "171  2025-12-08 12:32:35  Autos & Vehicles   \n",
       "172  2025-12-08 12:56:58    People & Blogs   \n",
       "173  2025-12-08 11:30:12            Sports   \n",
       "\n",
       "                                        shortsHashtags          fetchedDate  \\\n",
       "0    #ì†ì˜¤ê³µ, #ì¹ ì„ ê³µì£¼, #ì„œìœ ê¸°, #ì„¸ê¸°ìƒì‚¬, #í•œêµ­ì˜ìƒìë£Œì›, #ì˜ìƒìë£Œì›, #ì†...  2025-12-04 19:00:00   \n",
       "1    #bibletoktok, #movie, #bible, #animation, #Exo...  2025-12-04 19:00:00   \n",
       "2                                                  NaN  2025-12-04 19:00:00   \n",
       "3                                   #ì°¨ë°•, #ì¹´ë‹ˆë°œ, #shorts  2025-12-04 19:00:00   \n",
       "4                                                  NaN  2025-12-04 19:00:00   \n",
       "..                                                 ...                  ...   \n",
       "169                                                NaN  2025-12-08 13:10:00   \n",
       "170  #ë”K9, #ë”K9ì¤‘ê³ , #ë”K9ì¤‘ê³ ê°€ê²©, #ë”Kë² ì´ì§€ì‹œíŠ¸, #K9, #K9ì¤‘ê³ , ...  2025-12-08 13:10:00   \n",
       "171                                                NaN  2025-12-08 13:10:00   \n",
       "172  #Golf, #TallestGolfer, #JawDropping, #Shocking...  2025-12-08 13:10:00   \n",
       "173                           #yoga, #stretch, #sports  2025-12-08 13:10:00   \n",
       "\n",
       "    business_date  viewCount  likeCount  commentCount  subscriberCount  \\\n",
       "0      2025-12-04        364          0             0            13500   \n",
       "1      2025-12-04       1108         72             2              299   \n",
       "2      2025-12-04       5699          0             0           302000   \n",
       "3      2025-12-04       2464         22             1            19600   \n",
       "4      2025-12-04       3826         65            19           103000   \n",
       "..            ...        ...        ...           ...              ...   \n",
       "169    2025-12-08       1158         11             0            63700   \n",
       "170    2025-12-08        318          3             0            33400   \n",
       "171    2025-12-08       3601          0             1            50500   \n",
       "172    2025-12-08         30          1             0            68900   \n",
       "173    2025-12-08         16          1             0            19100   \n",
       "\n",
       "    channelTier                                          url  \\\n",
       "0        Tier 1  https://www.youtube.com/watch?v=6eVIT1NvSm4   \n",
       "1        Tier 1  https://www.youtube.com/watch?v=3yY6hkwkaOY   \n",
       "2        Tier 2  https://www.youtube.com/watch?v=QHfIUXvr3xc   \n",
       "3        Tier 1  https://www.youtube.com/watch?v=ksmZypA9aak   \n",
       "4        Tier 2  https://www.youtube.com/watch?v=HArxveHj8k0   \n",
       "..          ...                                          ...   \n",
       "169      Tier 1  https://www.youtube.com/watch?v=pMZtk7XNc1Y   \n",
       "170      Tier 1  https://www.youtube.com/watch?v=QZFW_JL8E40   \n",
       "171      Tier 1  https://www.youtube.com/watch?v=hitC3ZG4dTI   \n",
       "172      Tier 1  https://www.youtube.com/watch?v=s2S0jPX4BI4   \n",
       "173      Tier 1  https://www.youtube.com/watch?v=DPqVzUZUltA   \n",
       "\n",
       "              created_at                                      thumbnail_url  \n",
       "0    2025-12-04 19:00:00  https://i.ytimg.com/vi/6eVIT1NvSm4/maxresdefau...  \n",
       "1    2025-12-04 19:00:00  https://i.ytimg.com/vi/3yY6hkwkaOY/maxresdefau...  \n",
       "2    2025-12-04 19:00:00  https://i.ytimg.com/vi/QHfIUXvr3xc/maxresdefau...  \n",
       "3    2025-12-04 19:00:00  https://i.ytimg.com/vi/ksmZypA9aak/maxresdefau...  \n",
       "4    2025-12-04 19:00:00  https://i.ytimg.com/vi/HArxveHj8k0/maxresdefau...  \n",
       "..                   ...                                                ...  \n",
       "169  2025-12-08 13:10:00  https://i.ytimg.com/vi/pMZtk7XNc1Y/maxresdefau...  \n",
       "170  2025-12-08 13:10:00  https://i.ytimg.com/vi/QZFW_JL8E40/maxresdefau...  \n",
       "171  2025-12-08 13:10:00  https://i.ytimg.com/vi/hitC3ZG4dTI/maxresdefau...  \n",
       "172  2025-12-08 13:10:00  https://i.ytimg.com/vi/s2S0jPX4BI4/maxresdefau...  \n",
       "173  2025-12-08 13:10:00  https://i.ytimg.com/vi/DPqVzUZUltA/maxresdefau...  \n",
       "\n",
       "[174 rows x 18 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ê¸°ì¡´ì— ìˆ˜ì§‘í–ˆë˜ ë°ì´í„°ì—ì„œ ì¸ë„¤ì¼ ì»¬ëŸ¼ì„ ì¶”ê°€í•˜ì—¬ ìƒˆë¡­ê²Œ ìˆ˜ì§‘í•œ ë°ì´í„°ê°€ í•©ì³ì„œ\n",
    "# ì¸ë„¤ì¼ ì»¬ëŸ¼ ê¸°ì¤€ìœ¼ë¡œ ìƒˆë¡­ê²Œ ìˆ˜ì§‘í•œ ë°ì´í„°ë§Œ ê°€ì ¸ì˜´\n",
    "df = df[~df['thumbnail_url'].isna()].reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad512576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      https://i.ytimg.com/vi/6eVIT1NvSm4/maxresdefau...\n",
       "1      https://i.ytimg.com/vi/3yY6hkwkaOY/maxresdefau...\n",
       "2      https://i.ytimg.com/vi/QHfIUXvr3xc/maxresdefau...\n",
       "3      https://i.ytimg.com/vi/ksmZypA9aak/maxresdefau...\n",
       "4      https://i.ytimg.com/vi/HArxveHj8k0/maxresdefau...\n",
       "                             ...                        \n",
       "169    https://i.ytimg.com/vi/pMZtk7XNc1Y/maxresdefau...\n",
       "170    https://i.ytimg.com/vi/QZFW_JL8E40/maxresdefau...\n",
       "171    https://i.ytimg.com/vi/hitC3ZG4dTI/maxresdefau...\n",
       "172    https://i.ytimg.com/vi/s2S0jPX4BI4/maxresdefau...\n",
       "173    https://i.ytimg.com/vi/DPqVzUZUltA/maxresdefau...\n",
       "Name: thumbnail_url, Length: 174, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['thumbnail_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40508e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      https://www.youtube.com/watch?v=6eVIT1NvSm4\n",
       "1      https://www.youtube.com/watch?v=3yY6hkwkaOY\n",
       "2      https://www.youtube.com/watch?v=QHfIUXvr3xc\n",
       "3      https://www.youtube.com/watch?v=ksmZypA9aak\n",
       "4      https://www.youtube.com/watch?v=HArxveHj8k0\n",
       "                          ...                     \n",
       "169    https://www.youtube.com/watch?v=pMZtk7XNc1Y\n",
       "170    https://www.youtube.com/watch?v=QZFW_JL8E40\n",
       "171    https://www.youtube.com/watch?v=hitC3ZG4dTI\n",
       "172    https://www.youtube.com/watch?v=s2S0jPX4BI4\n",
       "173    https://www.youtube.com/watch?v=DPqVzUZUltA\n",
       "Name: url, Length: 174, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['url']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459bd28a",
   "metadata": {},
   "source": [
    "---\n",
    "ì¸ë„¤ì¼ ì´ë¯¸ì§€ ìº¡ì…˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cb0da48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.50, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "thumbnail captioning: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174/174 [08:13<00:00,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0                  ì†ì˜¤ê³µ,ì¹ ì„ ê³µì£¼ 2025ë…„ ì• ë‹ˆë©”ì´ì…˜ í•„ë¦„ ë””ì§€í„¸ ë³µì› í¬ëŸ¼   \n",
      "1  Exodus Part 7 â€” â€œThe Plague of Fliesâ€ Shorts  ...   \n",
      "2  Sugar on my ğŸ‘… #ì¶¤ì¶”ëŠ”ì„œìœ¤ #ì¶¤ì¶”ëŠ”ê³°ëŒ #ëŒ„ìŠ¤ #dance #kpop #...   \n",
      "3                               ê·¹ë½ ì°¨ë°•ì˜ ì‹œì‘ [ì¹´ë‹ˆë°œ íšŒì „ì‹œíŠ¸]   \n",
      "4            á„Œá…®á†¼á„€á…©á„á…¡ á„ƒá…µá†¯á„…á…¥á„€á…¡ á„Œá…¥á†¯á„ƒá…¢ á„‹á…¡á†« á„á…¡á„‚á…³á†« á„á…¡ #ì¤‘ê³ ì°¨   \n",
      "\n",
      "                                       thumbnail_url  \\\n",
      "0  https://i.ytimg.com/vi/6eVIT1NvSm4/maxresdefau...   \n",
      "1  https://i.ytimg.com/vi/3yY6hkwkaOY/maxresdefau...   \n",
      "2  https://i.ytimg.com/vi/QHfIUXvr3xc/maxresdefau...   \n",
      "3  https://i.ytimg.com/vi/ksmZypA9aak/maxresdefau...   \n",
      "4  https://i.ytimg.com/vi/HArxveHj8k0/maxresdefau...   \n",
      "\n",
      "                                       thumb_caption  \n",
      "0               a man sitting at a table with a cell  \n",
      "1  the bible is shown in the bible, and the bible...  \n",
      "2   a group of girls standing in front of a building  \n",
      "3             a van with the words ' s in the middle  \n",
      "4  a woman is holding a sign that says what is in...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import io                           # URLì—ì„œ ë°›ì€ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì—ì„œ íŒŒì¼ì²˜ëŸ¼ ë‹¤ë£¨ê¸° ìœ„í•´ ì‚¬ìš©\n",
    "from PIL import Image               # ì´ë¯¸ì§€ì—´ê¸° ,RGB\n",
    "import requests                     # ì¸ë„¤ì¼ URL ë‹¤ìš´ë¡œë“œ \n",
    "import torch                        # í…ì„œì—°ì‚°, GPU, no_grad()ë“± ë”¥ëŸ¬ë‹ì— ì‚¬ìš©\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration   \n",
    "# BlipProcessor: ì´ë¯¸ì§€ â†’ ëª¨ë¸ ì…ë ¥ í…ì„œë¡œ ë°”ê¿”ì¤Œ  // BlipForConditionalGeneration: ì‹¤ì œë¡œ ìº¡ì…˜ì„ ìƒì„±í•˜ëŠ” ì‹œí€€ìŠ¤ ìƒì„± ëª¨ë¸\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", device)\n",
    "\n",
    "# ëª¨ë¸ / í”„ë¡œì„¸ì„œ í•œ ë²ˆë§Œ ë¡œë“œ\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\") # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •, í…ì„œ ë³€í™˜, ì •ê·œí™” ë“±ì„ ì•Œì•„ì„œ ì²˜ë¦¬\n",
    "model = BlipForConditionalGeneration.from_pretrained(\n",
    "    \"Salesforce/blip-image-captioning-base\"\n",
    ").to(device)                      # ê°™ì€ ì´ë¦„ì˜ BLIP ìº¡ì…”ë‹ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ë‚´ë ¤ë°›ì•„ ë¡œë“œ // ì´ë¯¸ì§€ íŠ¹ì§•ì„ ì¸ì½”ë”©í•´ì„œ ë¬¸ì¥(ìº¡ì…˜)ì„ ìƒì„±í•˜ëŠ” ëª¨ë¸\n",
    "model.eval()\n",
    "\n",
    "# URLì—ì„œ ì´ë¯¸ì§€ë¥¼ ë°›ì•„ì„œ ìº¡ì…˜ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\n",
    "def caption_image_from_url(url: str, timeout: int = 10) -> str:\n",
    "    # URLì´ ë¹„ì–´ìˆê±°ë‚˜ NaNì´ë©´ ë°”ë¡œ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜\n",
    "    if not isinstance(url, str) or not url.strip():\n",
    "        return \"\"\n",
    "\n",
    "    try:\n",
    "        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n",
    "        resp = requests.get(url, timeout=timeout)\n",
    "        resp.raise_for_status() # 200ëŒ€ê°€ ì•„ë‹ˆë©´ ì˜ˆì™¸(ì—ëŸ¬)ë¥¼ ë°œìƒ , 404/500ì—ëŸ¬ê°€ ë‚˜ë©´ exceptë¡œ ë„˜ì–´ê° \n",
    "\n",
    "        # ë°”ì´íŠ¸ â†’ PIL ì´ë¯¸ì§€\n",
    "        image = Image.open(io.BytesIO(resp.content)).convert(\"RGB\")\n",
    "\n",
    "        # BLIP ì…ë ¥ ìƒì„±\n",
    "        # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ / ì •ê·œí™” / í…ì„œ ë³€í™˜ ì²˜ë¦¬í•´ì„œ  Pytorchí…ì„œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ \n",
    "        inputs = processor(image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        # ìº¡ì…˜ ìƒì„±\n",
    "        # ì—­ì „íŒŒìš© gradientë¥¼ ê³„ì‚°í•˜ì§€ ì•Šë„ë¡ // ì¶”ë¡  ëª¨ë“œì—ì„œ ë©”ëª¨ë¦¬ì™€ ì†ë„ë¥¼ ì ˆì•½í•˜ê¸° ìœ„í•´ í•„ìˆ˜\n",
    "        with torch.no_grad(): \n",
    "            out = model.generate(**inputs, max_new_tokens=30)\n",
    "\n",
    "        # í† í¬ë‚˜ì´ì € ì •ë³´ì— ë”°ë¼ ë‹¤ì‹œ ê¸€ìë¡œ ë˜ëŒë ¤ ì¤Œì¤Œ\n",
    "        # skip_special_tokens => ì‹œì‘ í† í°, ì¢…ë£Œ í† í° ê°™ì€ íŠ¹ìˆ˜ ê¸°í˜¸ë“¤ì€ ëºŒ \n",
    "        caption = processor.decode(out[0], skip_special_tokens=True) \n",
    "        \n",
    "        return caption\n",
    "\n",
    "    except Exception as e:\n",
    "        # ë¬¸ì œ ìƒê¸°ë©´ ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ë¹ˆ ë¬¸ìì—´ ë°˜í™˜\n",
    "        print(f\"[WARN] ìº¡ì…˜ ì‹¤íŒ¨: {url} ({e})\")\n",
    "        return \"\"\n",
    "\n",
    "# df['thumbnail_url'] ì „ì²´ì— ì ìš©í•´ì„œ ìƒˆ ì»¬ëŸ¼ ë§Œë“¤ê¸°\n",
    "tqdm.pandas(desc=\"thumbnail captioning\")\n",
    "df[\"thumb_caption\"] = df[\"thumbnail_url\"].progress_apply(caption_image_from_url)\n",
    "\n",
    "# í™•ì¸\n",
    "print(df[[\"title\", \"thumbnail_url\", \"thumb_caption\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7246ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df['thumb_caption']=='a man in a white shirt is holding a cell phone']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edaeb24",
   "metadata": {},
   "source": [
    "---\n",
    "LLM íŒŒì¸íŠœë‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a223dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: ./Utube_data/LLM_fine-tuning/training_titles.jsonl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "df = df.copy()\n",
    "\n",
    "# ì„±ëŠ¥ ì§€í‘œ ì˜ˆì‹œ: êµ¬ë…ì ëŒ€ë¹„ ì¡°íšŒìˆ˜\n",
    "df[\"views_per_sub\"] = df[\"viewCount\"] / (df[\"subscriberCount\"] + 1)\n",
    "\n",
    "# ìƒìœ„ 20%ë§Œ ì‚¬ìš© (ì›í•˜ì‹œëŠ” ë¹„ìœ¨ë¡œ ì¡°ì ˆ)\n",
    "cut = df[\"views_per_sub\"].quantile(0.8)\n",
    "top = df[df[\"views_per_sub\"] >= cut].copy()\n",
    "\n",
    "def make_user_prompt(row):\n",
    "    desc_val = row.get(\"description\")\n",
    "    if pd.isna(desc_val):\n",
    "        desc_val = \"\"\n",
    "    desc_snip = str(desc_val)[:120]\n",
    "\n",
    "    return (\n",
    "        \"ë‹¹ì‹ ì€ í•œêµ­ì–´ ìœ íŠœë¸Œ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\\n\"\n",
    "        \"ë‹¤ìŒ ì •ë³´ë¥¼ ë³´ê³  ì¡°íšŒìˆ˜ê°€ ì˜ ë‚˜ì˜¬ ë§Œí•œ ì œëª©ì„ 1ê°œë§Œ ì¶”ì²œí•´ ì£¼ì„¸ìš”.\\n\\n\"\n",
    "        f\"ì±„ë„ êµ¬ë…ì í‹°ì–´: {row.get('channelTier')}\\n\"\n",
    "        f\"ì¹´í…Œê³ ë¦¬: {row.get('category')}\\n\"\n",
    "        f\"ì˜ìƒ íƒ€ì…: {'Shorts' if row.get('is_short') else 'Long-form'}\\n\"\n",
    "        f\"ì¸ë„¤ì¼ ë¬˜ì‚¬: {row.get('thumb_caption')}\\n\"\n",
    "        f\"ì˜ìƒ ì„¤ëª…(ìš”ì•½): {desc_snip}\\n\\n\"\n",
    "        \"ì¡°ê±´:\\n\"\n",
    "        \"- í•œêµ­ì–´ë¡œ ì‘ì„±\\n\"\n",
    "        \"- ë‚šì‹œì„±ì€ í”¼í•˜ë˜ í˜¸ê¸°ì‹¬ì„ ê°•í•˜ê²Œ ìê·¹\\n\"\n",
    "        \"- 30ì ì´ë‚´\\n\"\n",
    "        \"- ì´ëª¨ì§€ëŠ” ìµœëŒ€ 1ê°œê¹Œì§€ë§Œ ì‚¬ìš©\\n\\n\"\n",
    "        \"ì œëª©:\"\n",
    "    )\n",
    "\n",
    "out_path = \"./Utube_data/LLM_fine-tuning/training_titles.jsonl\"\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in top.iterrows():\n",
    "        user_content = make_user_prompt(row)\n",
    "        assistant_content = row[\"title\"]\n",
    "\n",
    "        record = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ í•œêµ­ì–´ ìœ íŠœë¸Œ ì œëª© ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"},\n",
    "                {\"role\": \"user\", \"content\": user_content},\n",
    "                {\"role\": \"assistant\", \"content\": assistant_content},\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"saved:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8a62ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63444d24d5924970b0692dc85c78224a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YUN\\miniconda3\\envs\\my_mL\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\YUN\\.cache\\huggingface\\hub\\models--Qwen--Qwen2.5-0.5B-Instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2501d41d6e6740b9815017583a549e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e973ab491c44b008a1dd24e86ddb43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f021c19c135f4f93b9cb6c079f06015c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932c54784421486697649a9306af7e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac5698f970c4a338ec1d27acc68061f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# -------------------------------------------------\n",
    "# ê¸°ë³¸ ì„¤ì •\n",
    "# -------------------------------------------------\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "DATA_FILE = \"./Utube_data/LLM_fine-tuning/training_titles.jsonl\"\n",
    "OUTPUT_DIR = \"./Utube_data/yt_title_lora\"\n",
    "MAX_LEN = 256  # í•œ ìƒ˜í”Œ ìµœëŒ€ í† í° ê¸¸ì´\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device_map = \"auto\" if use_cuda else \"cpu\"\n",
    "dtype = torch.float16 if use_cuda else torch.float32\n",
    "\n",
    "# -------------------------------------------------\n",
    "# í† í¬ë‚˜ì´ì € / ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ\n",
    "# -------------------------------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "# pad í† í°ì´ ì—†ìœ¼ë©´ eos í† í°ì„ padë¡œ ê²¸ìš©\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=dtype,\n",
    "    device_map=device_map,\n",
    ")\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# LoRA ì„¤ì • \n",
    "# -------------------------------------------------\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",      # CAUSAL_LM => ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ í•œ í† í°ì”© ì˜ˆì¸¡í•˜ëŠ” ì–¸ì–´ ëª¨ë¸ì„ ì˜ë¯¸\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters() \n",
    "# trainable params: 2,179,072 || all params: 1,545,893,376 || trainable%: 0.1410 ì¶œë ¥ í•´ì¤Œ (íŒŒë¼ë¯¸í„° ìˆ˜)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# JSONL ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "#    training_titles.jsonl ì•ˆì˜ ê° ì¤„ì€\n",
    "#    {\"messages\": [...]} êµ¬ì¡°\n",
    "# -------------------------------------------------\n",
    "\n",
    "raw_dset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\"train\": DATA_FILE},\n",
    "    split=\"train\",  \n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# chat_template + í† í¬ë‚˜ì´ì¦ˆ\n",
    "#    - batched=True ì´ê¸° ë•Œë¬¸ì— ì—¬ëŸ¬ ìƒ˜í”Œì„ í•œ ë²ˆì— ì²˜ë¦¬\n",
    "#    - padding=\"max_length\" ë¡œ ê¸¸ì´ ë§ì¶”ê¸°\n",
    "#    - labels = input_ids ë³µì‚¬\n",
    "# -------------------------------------------------\n",
    "def tokenize_function(examples):\n",
    "    # examples[\"messages\"] : ê° ìƒ˜í”Œì˜ messages ë¦¬ìŠ¤íŠ¸\n",
    "    texts = [\n",
    "        tokenizer.apply_chat_template(\n",
    "            msgs,\n",
    "            tokenize=False,                # ì•„ì§ ìˆ«ì í† í°ìœ¼ë¡œ ë§Œë“¤ì§€ë§ê³  ë¬¸ìì—´ë¼ë¦¬ \n",
    "            add_generation_prompt=False    # assistant ë‹µë³€ê¹Œì§€ í¬í•¨í•´ì„œ í•™ìŠµ // assistant ë‹µë³€ì€ ì´ë¯¸ ìˆìœ¼ë‹ˆ ì¶”ê°€ í”„ë¡¬í¬íŠ¸ X \n",
    "        )\n",
    "        for msgs in examples[\"messages\"]\n",
    "    ]                                       # system + user + assistant í•©ì³ì„œ í•œì¤„ LLM text ë¦¬ìŠ¤íŠ¸ \n",
    "    \n",
    "\n",
    "    # ìœ„ì—ì„œ ë§Œë“  LLM í•œì¤„ textë¥¼ ìˆ«ì í† í°ìœ¼ë¡œ ë°”ê¾¸ê³  \n",
    "    # MAX_LENê¸¸ì´ë¡œ í†µì¼ \n",
    "    batch = tokenizer(\n",
    "        texts,\n",
    "        padding=\"max_length\",       # ëª¨ë“  ìƒ˜í”Œ ê¸¸ì´ë¥¼ MAX_LENì— ë§ì¶° íŒ¨ë”©\n",
    "        truncation=True,            # MAX_LENë³´ë‹¤ ê¸¸ì´ê°€ ê¸¸ë©´ ìë¦„ (ë’·ìª½)\n",
    "        max_length=MAX_LEN,     \n",
    "    )\n",
    "\n",
    "\n",
    "    # ì–¸ì–´ëª¨ë¸ íŒŒì¸íŠœë‹: labels = input_ids\n",
    "    # í† í°í™” => ë¼ë²¨ \n",
    "    batch[\"labels\"] = batch[\"input_ids\"].copy()\n",
    "    return batch\n",
    "\n",
    "\n",
    "tokenized = raw_dset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=raw_dset.column_names,  # ì›ë³¸ ì»¬ëŸ¼(messages) ì œê±°\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# ë°ì´í„° ì½œë ˆì´í„° \n",
    "# -------------------------------------------------\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,      # Trueë©´ ì¼ë¶€ í† í°ì„ maskë¡œ ê°€ë¦¼ \n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# í•™ìŠµ ì„¤ì •\n",
    "# -------------------------------------------------\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,              # í•™ìŠµ ê²°ê³¼ ì €ì¥ ê²½ë¡œ \n",
    "    per_device_train_batch_size=1,      # batch_size ì„¤ì • \n",
    "    gradient_accumulation_steps=16,      # ê¸°ìš¸ê¸° ëˆ„ì  ìŠ¤í… ìˆ˜ë¥¼ ì§€ì •\n",
    "    num_train_epochs=3,                 # ì „ì²´ ë°ì´í„° í•™ìŠµ ë°˜ë³µ íšŸìˆ˜ \n",
    "    learning_rate=2e-4,                 # í•™ìŠµë¥  ì§€ì • \n",
    "    fp16=use_cuda,                      # GPU ìˆì„ ë•Œë§Œ fp16 ì‚¬ìš©\n",
    "    logging_steps=50,                   # ë¡œê·¸ ì¶œë ¥ ìŠ¤í… \n",
    "\n",
    "    save_steps=500,                     # ì²´í¬í¬ì¸íŠ¸ ìŠ¤í…   \n",
    "    save_total_limit=3,                 # ì²´í¬í¬ì¸íŠ¸ ìµœëŒ€ ê°¯ìˆ˜ \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized,            # í•™ìŠµí•  ë°ì´í„° ì…‹ \n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# LoRA ì–´ëŒ‘í„° + í† í¬ë‚˜ì´ì € ì €ì¥\n",
    "# -------------------------------------------------\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "print(\"Saved LoRA adapter and tokenizer to:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02038bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded LoRA model from ./Utube_data/yt_title_lora\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# í…ì„œ ì—°ì‚°ê³¼ ë””ë°”ì´ìŠ¤ ê´€ë¦¬ì— ì‚¬ìš©\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# ëª¨ë¸ ì´ë¦„ë§Œ ì£¼ë©´ ê·¸ì— ë§ëŠ” í† í¬ë‚˜ì´ì €ë¥¼ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ëŠ” í´ë˜ìŠ¤ \n",
    "# ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì–¸ì–´ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ëŠ” í´ë˜ìŠ¤\n",
    "from peft import PeftModel\n",
    "# oRA ê°™ì€ PEFT ì–´ëŒ‘í„°ë¥¼ ë² ì´ìŠ¤ ëª¨ë¸ì— í•©ì³ì„œ ì‚¬ìš©í•˜ëŠ” ë˜í¼ ëª¨ë¸\n",
    "\n",
    "\n",
    "# í—ˆê¹…í˜ì´ìŠ¤ gpt \n",
    "BASE_MODEL = \"Qwen/Qwen2.5-1.5B-Instruct\" \n",
    "ADAPTER_DIR = \"./Utube_data/yt_title_lora\"\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device_map = \"auto\" if use_cuda else \"cpu\"\n",
    "dtype = torch.float16 if use_cuda else torch.float32\n",
    "\n",
    "# í† í¬ë‚˜ì´ì €\n",
    "tokenizer = AutoTokenizer.from_pretrained(ADAPTER_DIR, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "# ë² ì´ìŠ¤ ëª¨ë¸ + LoRA ì–´ëŒ‘í„° ë¡œë“œ\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    torch_dtype=dtype,\n",
    "    device_map=device_map,\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ë‘ê°œ í•©ì¹œê²ƒ (Qwen + ë‚´ ë°ì´í„°ì˜ LoRA)\n",
    "model = PeftModel.from_pretrained(base_model, ADAPTER_DIR)\n",
    "model.eval()\n",
    "\n",
    "print(\"loaded LoRA model from\", ADAPTER_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de0d7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_messages(row):\n",
    "\n",
    "    desc = row.get(\"description\")\n",
    "    if desc is None or (isinstance(desc, float) and pd.isna(desc)):\n",
    "        desc_snip = \"\"\n",
    "    else:\n",
    "        desc_snip = str(desc)[:120]\n",
    "    \n",
    "    # ì„¤ëª…ë€ ì—†ìœ¼ë©´ ê³µë°± ë„ˆë¬´ ê¸¸ë©´ 120ìê¹Œì§€  \n",
    "\n",
    "    thumb = row.get(\"thumb_caption\")\n",
    "    if thumb is None or (isinstance(thumb, float) and pd.isna(thumb)):\n",
    "        thumb_txt = \"ì •ë³´ ì—†ìŒ\"\n",
    "    else:\n",
    "        thumb_txt = str(thumb)\n",
    "\n",
    "\n",
    "    channel_tier = row.get(\"channelTier\", \"Unknown\")\n",
    "    category = row.get(\"category\", \"Unknown\")\n",
    "    is_short = bool(row.get(\"is_short\", False))\n",
    "\n",
    "    user_content = (\n",
    "        \"ë‹¹ì‹ ì€ í•œêµ­ì–´ ìœ íŠœë¸Œ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\\n\"\n",
    "        \"ë‹¤ìŒ ì •ë³´ë¥¼ ë³´ê³  ì¡°íšŒìˆ˜ê°€ ì˜ ë‚˜ì˜¬ ë§Œí•œ ì œëª©ì„ 1ê°œë§Œ ì¶”ì²œí•´ ì£¼ì„¸ìš”.\\n\\n\"\n",
    "        f\"ì±„ë„ êµ¬ë…ì í‹°ì–´: {channel_tier}\\n\"\n",
    "        f\"ì¹´í…Œê³ ë¦¬: {category}\\n\"\n",
    "        f\"ì˜ìƒ íƒ€ì…: {'Shorts' if is_short else 'Long-form'}\\n\"\n",
    "        f\"ì¸ë„¤ì¼ ë¬˜ì‚¬: {thumb_txt}\\n\"\n",
    "        f\"ì˜ìƒ ì„¤ëª…(ìš”ì•½): {desc_snip}\\n\\n\"\n",
    "        \"ì¡°ê±´:\\n\"\n",
    "        \"- í•œêµ­ì–´ë¡œ ì‘ì„±\\n\"\n",
    "        \"- ë‚šì‹œì„±ì€ í”¼í•˜ë˜ í˜¸ê¸°ì‹¬ì„ ê°•í•˜ê²Œ ìê·¹\\n\"\n",
    "        \"- 30ì ì´ë‚´\\n\"\n",
    "        \"- ì´ëª¨ì§€ëŠ” ìµœëŒ€ 1ê°œê¹Œì§€ë§Œ ì‚¬ìš©\\n\\n\"\n",
    "        \"ì œëª©:\"\n",
    "    )\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ í•œêµ­ì–´ ìœ íŠœë¸Œ ì œëª© ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"},\n",
    "        {\"role\": \"user\", \"content\": user_content},\n",
    "    ]\n",
    "    return messages\n",
    "\n",
    "\n",
    "def generate_title_for_row(row, max_new_tokens=32, temperature=0.7, top_p=0.9):\n",
    "    messages = build_messages(row)\n",
    "\n",
    "    # chat í…œí”Œë¦¿ ì ìš©í•´ì„œ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´ ë§Œë“¤ê¸°\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,  # assistant ì°¨ë¡€ë¼ê³  ì•Œë ¤ì¤Œ\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # í† í°ë“¤ì„ ìë™ìœ¼ë¡œ ìƒì„±í•´ ì£¼ëŠ” ê³ ìˆ˜ì¤€ ë©”ì„œë“œ\n",
    "        output_ids = model.generate(\n",
    "            **inputs,                           # í† í¬ë‚˜ì´ì €ê°€ ë§Œë“¤ì–´ ì¤€ ì…ë ¥ í…ì„œë“¤ì„ ê·¸ëŒ€ë¡œ ëª¨ë¸ì— ì „ë‹¬\n",
    "            max_new_tokens=max_new_tokens,      # ìƒˆë¡œ ìƒì„±í•  í† í°ì˜ ìµœëŒ€ ê°œìˆ˜ë¥¼ ì§€ì •\n",
    "            do_sample=True,                     # ê³ ì •ì ìœ¼ë¡œ ë†’ì€ í† í°ë§Œ ë‚˜ì˜¤ëŠ”ê²Œ ì•„ë‹Œ ê³„ì† ë‹¤ë¥¸ ê²°ê³¼ \n",
    "            top_p=top_p,\n",
    "\n",
    "            temperature=temperature,\n",
    "            # 1.0ì´ë©´ ì›ë˜ í™•ë¥  ë¶„í¬ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "            # 1.0ë³´ë‹¤ í¬ë©´ ë¶„í¬ë¥¼ ë” í‰í‰í•˜ê²Œ ë§Œë“¤ì–´ ëœ í™•ë¥  ë†’ì€ í† í°ë„ ë½‘í ê°€ëŠ¥ì„±ì´ ì»¤ì§\n",
    "            # 1.0ë³´ë‹¤ ì‘ìœ¼ë©´ ë¶„í¬ë¥¼ ë” ë¾°ì¡±í•˜ê²Œ ë§Œë“¤ì–´ ê°€ì¥ ìœ ë ¥í•œ í›„ë³´ ìª½ìœ¼ë¡œ ë” ê°•í•˜ê²Œ ì ë¦¼\n",
    "\n",
    "            pad_token_id=tokenizer.eos_token_id,    # eos padding ( ê¸¸ì´ê°€ ë¶€ì¡±í•˜ë©´ eos(ë)ì„ ì±„ì›Œì„œ padding ) \n",
    "        )\n",
    "\n",
    "    # ëª¨ë¸ì´ ìƒì„±í•œ ì œëª© \n",
    "    full_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # \"ì œëª©:\" ì´í›„ë§Œ ì˜ë¼ì„œ ì‹¤ì œ ì œëª©ë§Œ ë½‘ê¸°\n",
    "    idx = full_text.rfind(\"ì œëª©:\")      # \"ì œëª©:\"ì„ ì°¾ì§€ ëª»í•˜ë©´ -1\n",
    "    if idx != -1:\n",
    "        title = full_text[idx + len(\"ì œëª©:\"):].strip()\n",
    "    else:\n",
    "        # í˜¹ì‹œ ëª» ì°¾ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ë§ˆì§€ë§‰ ì¤„ë§Œ ì‚¬ìš©\n",
    "        title = full_text.strip().splitlines()[-1].strip()\n",
    "    \n",
    "    # assistant ì œê±° ( ì¶œë ¥í• ë•Œ assistantë„ ê°™ì´ ì¶œë ¥ ë¨ )\n",
    "    t = title.lstrip()\n",
    "    for assistants in [\"assistant\", \"Assistant\", \"assistant:\", \"Assistant:\"]:\n",
    "        if t.startswith(assistants):                         # assistants ë¦¬ìŠ¤íŠ¸ 4ê°œì¤‘ í•˜ë‚˜ë¡œ ì‹œì‘í•œë‹¤ë©´ \n",
    "            t = t[len(assistants):].lstrip(\" :-\\u3000\")      # ê¸¸ì´ë§Œí¼ ìŠ¬ë¼ì´ì‹±í•˜ê³  ê³µë°±, :, -, ì‚­ì œì œ\n",
    "            break\n",
    "    title = t\n",
    "\n",
    "    return title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8aa26e",
   "metadata": {},
   "source": [
    "---\n",
    "- ê²°ê³¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf762e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ì¸ë±ìŠ¤ në²ˆ í–‰\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m title_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m160\u001b[39m]\n\u001b[0;32m      4\u001b[0m row \u001b[38;5;241m=\u001b[39m title_df\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[0;32m      5\u001b[0m gen_title \u001b[38;5;241m=\u001b[39m generate_title_for_row(row)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# ì¸ë±ìŠ¤ në²ˆ í–‰\n",
    "title_df = df.iloc[160]\n",
    "\n",
    "row = title_df.to_dict()\n",
    "gen_title = generate_title_for_row(row)\n",
    "print(\"ì›ë˜ ì œëª© :\", title_df[\"title\"])\n",
    "print(\"ì¶”ì²œ ì œëª© :\", gen_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c457e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                53\n",
       "videoId                                                  V0LbOmdg2BQ\n",
       "title              I need to poop - POPPY PLAYTIME CHAPTER 3 | GH...\n",
       "description        @GH.S  \\nğŸŸ£ GH'STUDIO : GH'S, PP, JJINSTONE, JN...\n",
       "channelTitle                                                    GH'S\n",
       "publishedAt                                      2024-08-23 18:14:24\n",
       "category                                                      Gaming\n",
       "shortsHashtags                                                   NaN\n",
       "fetchedDate                                      2025-12-05 21:00:00\n",
       "business_date                                             2025-12-05\n",
       "viewCount                                                   14669713\n",
       "likeCount                                                     356999\n",
       "commentCount                                                    2570\n",
       "subscriberCount                                             26300000\n",
       "channelTier                                                   Tier 4\n",
       "url                      https://www.youtube.com/watch?v=V0LbOmdg2BQ\n",
       "created_at                                       2025-12-05 21:00:00\n",
       "thumbnail_url      https://i.ytimg.com/vi/V0LbOmdg2BQ/maxresdefau...\n",
       "views_per_sub                                               0.557784\n",
       "thumb_caption      a cartoon character with a purple cat on his head\n",
       "Name: 79, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e51ce92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <class 'peft.peft_model.PeftModelForCausalLM'>\n",
      "base_model <class 'peft.tuners.lora.model.LoraModel'>\n",
      "base_model.model <class 'transformers.models.qwen2.modeling_qwen2.Qwen2ForCausalLM'>\n",
      "base_model.model.model <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Model'>\n",
      "base_model.model.model.embed_tokens <class 'torch.nn.modules.sparse.Embedding'>\n",
      "base_model.model.model.layers <class 'torch.nn.modules.container.ModuleList'>\n",
      "base_model.model.model.layers.0 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.0.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.0.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.0.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.0.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.0.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.0.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.0.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.0.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.0.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.0.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.0.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.0.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.0.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.0.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.1 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.1.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.1.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.1.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.1.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.1.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.1.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.1.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.1.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.1.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.1.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.1.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.1.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.1.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.1.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.2 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.2.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.2.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.2.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.2.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.2.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.2.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.2.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.2.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.2.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.2.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.2.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.2.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.2.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.2.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.3 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.3.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.3.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.3.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.3.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.3.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.3.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.3.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.3.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.3.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.3.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.3.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.3.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.3.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.3.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.4 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.4.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.4.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.4.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.4.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.4.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.4.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.4.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.4.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.4.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.4.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.4.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.4.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.4.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.4.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.5 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.5.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.5.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.5.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.5.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.5.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.5.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.5.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.5.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.5.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.5.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.5.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.5.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.5.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.5.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.6 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.6.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.6.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.6.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.6.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.6.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.6.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.6.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.6.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.6.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.6.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.6.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.6.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.6.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.6.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.7 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.7.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.7.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.7.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.7.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.7.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.7.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.7.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.7.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.7.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.7.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.7.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.7.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.7.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.7.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.8 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.8.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.8.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.8.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.8.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.8.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.8.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.8.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.8.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.8.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.8.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.8.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.8.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.8.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.8.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.9 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.9.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.9.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.9.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.9.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.9.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.9.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.9.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.9.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.9.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.9.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.9.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.9.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.9.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.9.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.10 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.10.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.10.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.10.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.10.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.10.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.10.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.10.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.10.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.10.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.10.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.10.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.10.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.10.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.10.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.11 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.11.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.11.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.11.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.11.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.11.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.11.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.11.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.11.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.11.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.11.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.11.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.11.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.11.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.11.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.12 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.12.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.12.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.12.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.12.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.12.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.12.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.12.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.12.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.12.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.12.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.12.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.12.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.12.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.12.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.13 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.13.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.13.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.13.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.13.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.13.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.13.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.13.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.13.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.13.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.13.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.13.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.13.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.13.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.13.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.14 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.14.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.14.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.14.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.14.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.14.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.14.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.14.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.14.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.14.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.14.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.14.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.14.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.14.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.14.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.15 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.15.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.15.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.15.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.15.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.15.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.15.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.15.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.15.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.15.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.15.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.15.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.15.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.15.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.15.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.16 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.16.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.16.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.16.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.16.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.16.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.16.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.16.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.16.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.16.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.16.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.16.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.16.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.16.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.16.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.17 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.17.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.17.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.17.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.17.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.17.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.17.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.17.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.17.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.17.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.17.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.17.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.17.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.17.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.17.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.18 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.18.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.18.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.18.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.18.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.18.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.18.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.18.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.18.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.18.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.18.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.18.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.18.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.18.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.18.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.19 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.19.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.19.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.19.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.19.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.19.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.19.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.19.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.19.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.19.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.19.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.19.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.19.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.19.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.19.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.20 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.20.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.20.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.20.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.20.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.20.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.20.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.20.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.20.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.20.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.20.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.20.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.20.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.20.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.20.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.21 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.21.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.21.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.21.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.21.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.21.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.21.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.21.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.21.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.21.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.21.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.21.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.21.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.21.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.21.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.22 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.22.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.22.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.22.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.22.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.22.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.22.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.22.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.22.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.22.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.22.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.22.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.22.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.22.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.22.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.23 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.23.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.23.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.23.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.23.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.23.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.23.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.23.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.23.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.23.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.23.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.23.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.23.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.23.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.23.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.24 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.24.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.24.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.24.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.24.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.24.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.24.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.24.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.24.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.24.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.24.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.24.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.24.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.24.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.24.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.25 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.25.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.25.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.25.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.25.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.25.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.25.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.25.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.25.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.25.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.25.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.25.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.25.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.25.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.25.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.26 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.26.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.26.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.26.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.26.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.26.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.26.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.26.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.26.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.26.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.26.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.26.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.26.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.26.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.26.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.27 <class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>\n",
      "base_model.model.model.layers.27.self_attn <class 'transformers.models.qwen2.modeling_qwen2.Qwen2Attention'>\n",
      "base_model.model.model.layers.27.self_attn.q_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.27.self_attn.q_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.27.self_attn.k_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.27.self_attn.v_proj <class 'peft.tuners.lora.layer.Linear'>\n",
      "base_model.model.model.layers.27.self_attn.v_proj.base_layer <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_dropout <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_dropout.default <class 'torch.nn.modules.dropout.Dropout'>\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_embedding_A <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_embedding_B <class 'torch.nn.modules.container.ParameterDict'>\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_magnitude_vector <class 'torch.nn.modules.container.ModuleDict'>\n",
      "base_model.model.model.layers.27.self_attn.o_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.27.mlp <class 'transformers.models.qwen2.modeling_qwen2.Qwen2MLP'>\n",
      "base_model.model.model.layers.27.mlp.gate_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.27.mlp.up_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.27.mlp.down_proj <class 'torch.nn.modules.linear.Linear'>\n",
      "base_model.model.model.layers.27.mlp.act_fn <class 'torch.nn.modules.activation.SiLU'>\n",
      "base_model.model.model.layers.27.input_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.layers.27.post_attention_layernorm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.norm <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RMSNorm'>\n",
      "base_model.model.model.rotary_emb <class 'transformers.models.qwen2.modeling_qwen2.Qwen2RotaryEmbedding'>\n",
      "base_model.model.lm_head <class 'torch.nn.modules.linear.Linear'>\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    print(name, type(module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20c4f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_layer\n",
      "default\n",
      "down_proj\n",
      "gate_proj\n",
      "k_proj\n",
      "o_proj\n",
      "up_proj\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "proj_suffixes = set()\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Linear) and \"proj\" in name:\n",
    "        suffix = name.split(\".\")[-1]\n",
    "        proj_suffixes.add(suffix)\n",
    "\n",
    "for s in sorted(proj_suffixes):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de9f9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c0e736",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_mL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
